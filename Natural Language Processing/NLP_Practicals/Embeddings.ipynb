{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Word Embedding technique using Embeddings in Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This program iterates through the list fishes and compares each element with its adjacent element.', 'If the left-side element is greater than the right-side element, it removes the right-side element from the list.', 'It continues this process until it reaches the end of the list. Finally, it prints the modified list.']\n"
     ]
    }
   ],
   "source": [
    "sentences = ['This program iterates through the list fishes and compares each element with its adjacent element.' ,\n",
    "             'If the left-side element is greater than the right-side element, it removes the right-side element from the list.', \n",
    "             'It continues this process until it reaches the end of the list. Finally, it prints the modified list.']\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **One Hot Representation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2152, 43, 7595, 4083, 529, 6450, 5929, 6456, 4518, 8567, 5455, 4313, 6607, 5718, 5455], [3064, 529, 2839, 6112, 5455, 3852, 5949, 8432, 529, 8929, 6112, 5455, 8502, 5442, 529, 8929, 6112, 5455, 5053, 529, 6450], [8502, 454, 2152, 8513, 2816, 8502, 3041, 529, 2154, 766, 529, 6450, 2216, 8502, 7631, 529, 8629, 6450]]\n"
     ]
    }
   ],
   "source": [
    "one_hot_repr = [one_hot(word, vocabulary_size) for word in sentences]\n",
    "print(one_hot_repr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we are getting the index from the vocabulary, where the word is present on which index in vocabulry.\n",
    "- If we see the index of **the** is 529 in vocabulary, so wherever there is **the** in any sentence the same index will be returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now in our sentences, each and every sentence length is different.\n",
    "- If I need to train this in neural network, my sentence length should be same for all sentences.\n",
    "- That's why we use post and pre padding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Word Embedding Representation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 18, 18]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(sentence.split()) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This pad_sequences will add the padding wherver there are less number of words in any sentence that the maximum sentence length.\n",
    "- Either it will add 0 at first or at last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 2152   43 7595 4083  529 6450 5929 6456 4518 8567 5455\n",
      "  4313 6607 5718 5455]\n",
      " [6112 5455 3852 5949 8432  529 8929 6112 5455 8502 5442  529 8929 6112\n",
      "  5455 5053  529 6450]\n",
      " [8502  454 2152 8513 2816 8502 3041  529 2154  766  529 6450 2216 8502\n",
      "  7631  529 8629 6450]]\n"
     ]
    }
   ],
   "source": [
    "max_sentence_len = max([len(sentence.split()) for sentence in sentences])\n",
    "embedded_sentences = pad_sequences(one_hot_repr, padding='pre', maxlen=max_sentence_len)\n",
    "print(embedded_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now as we know, the first sentence has 15 words, and max words length is 18, so it will add 3 0s at the start of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 18)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now the input size is fixed for all the different length sentences.\n",
    "- Now we have to convert this one hot representation into vectors using Word2Vec.\n",
    "- In Word2Vec we have to define the feature representation size to create a vector of that size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size, feature_dim, input_length = max_sentence_len))\n",
    "model.compile('adam', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 18, 10)            100000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100,000\n",
      "Trainable params: 100,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n"
     ]
    }
   ],
   "source": [
    "sent_1 = model.predict(embedded_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04958859, -0.00029375,  0.0021411 , -0.03382953,  0.00518345,\n",
       "        -0.02229652, -0.04717842, -0.015091  , -0.00550201, -0.04358589],\n",
       "       [-0.04958859, -0.00029375,  0.0021411 , -0.03382953,  0.00518345,\n",
       "        -0.02229652, -0.04717842, -0.015091  , -0.00550201, -0.04358589],\n",
       "       [-0.04958859, -0.00029375,  0.0021411 , -0.03382953,  0.00518345,\n",
       "        -0.02229652, -0.04717842, -0.015091  , -0.00550201, -0.04358589],\n",
       "       [-0.0321614 , -0.04003553,  0.01037462, -0.04467133, -0.01149772,\n",
       "         0.02548233,  0.01720269,  0.02731569, -0.0404562 ,  0.02892831],\n",
       "       [ 0.04773477,  0.03213054, -0.00138054,  0.04010015,  0.00552629,\n",
       "         0.00278773, -0.01416502,  0.03941151, -0.02107297,  0.04168974],\n",
       "       [-0.03581516, -0.03247398, -0.00897322, -0.03929315,  0.01203708,\n",
       "        -0.01428032, -0.04475442, -0.0170147 ,  0.02185266,  0.02517873],\n",
       "       [-0.04949846,  0.03666887, -0.00311844, -0.01789719,  0.02648691,\n",
       "        -0.01334971,  0.02618753, -0.04231563,  0.02562732,  0.00550633],\n",
       "       [ 0.04887059,  0.0157407 , -0.03330671,  0.01143346,  0.01701764,\n",
       "        -0.02079874, -0.01730059, -0.0272251 ,  0.00132239, -0.00146746],\n",
       "       [ 0.02358199,  0.03654018,  0.04605527, -0.00236931,  0.04934983,\n",
       "        -0.04221008, -0.03040319,  0.0329848 , -0.0373503 , -0.03928951],\n",
       "       [-0.01777049,  0.0124418 ,  0.02752269,  0.04995463, -0.01762147,\n",
       "        -0.02970754, -0.03005123, -0.01620947,  0.01722231, -0.01732129],\n",
       "       [-0.01653359,  0.0495385 ,  0.00689663,  0.03831773, -0.01826596,\n",
       "        -0.04043323,  0.01632031,  0.02889093,  0.00748899,  0.03500367],\n",
       "       [-0.01216491,  0.02950701,  0.02466483,  0.04924745, -0.0479587 ,\n",
       "        -0.01578967,  0.03805101, -0.04657843,  0.00062101, -0.03851372],\n",
       "       [ 0.02538813,  0.04515164,  0.03230405,  0.00876521, -0.04674722,\n",
       "         0.00134692, -0.03237935, -0.01041373,  0.01929939,  0.00256276],\n",
       "       [-0.03248184, -0.03444965, -0.04710479, -0.04286117, -0.03676959,\n",
       "        -0.01241045,  0.02784777,  0.03569481,  0.00245693, -0.00958955],\n",
       "       [ 0.00796244,  0.03208606, -0.01192455, -0.02478045, -0.0315236 ,\n",
       "        -0.01755112, -0.02834709,  0.00140562, -0.02609841,  0.04518939],\n",
       "       [ 0.04929428,  0.01822109, -0.01212648,  0.04524609, -0.01098504,\n",
       "         0.00289847,  0.00870733,  0.02494467,  0.03783598,  0.03371317],\n",
       "       [-0.03582419, -0.01957842, -0.02502049, -0.02063072, -0.01305055,\n",
       "         0.03561839, -0.04539103, -0.02041718,  0.00889117, -0.04979627],\n",
       "       [-0.03248184, -0.03444965, -0.04710479, -0.04286117, -0.03676959,\n",
       "        -0.01241045,  0.02784777,  0.03569481,  0.00245693, -0.00958955]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0, 2152,   43, 7595, 4083,  529, 6450, 5929, 6456,\n",
       "       4518, 8567, 5455, 4313, 6607, 5718, 5455])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now as in embedded_sentences[0], we have first three words as 0.\n",
    "- Hence the vectors are also same in embedding layer output for first three words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
