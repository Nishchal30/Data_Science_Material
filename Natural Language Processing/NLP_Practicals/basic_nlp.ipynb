{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                NLP can also help you write better content by providing feedback, suggestions, \n",
      "                and insights on your writing style, tone, readability, grammar, and SEO. \n",
      "                You can use NLP tools to check and improve your spelling, punctuation, vocabulary, \n",
      "                and sentence structure. You can also use NLP tools to measure and adjust your \n",
      "                content's sentiment, emotion, and personality to match your brand voice and your \n",
      "                audience's preferences. For example, you can use a tool like Hemingway to make your \n",
      "                content more clear and concise, or use a tool like Grammarly to enhance your writing \n",
      "                skills and avoid errors.\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "paragraph = '''\n",
    "                NLP can also help you write better content by providing feedback, suggestions, \n",
    "                and insights on your writing style, tone, readability, grammar, and SEO. \n",
    "                You can use NLP tools to check and improve your spelling, punctuation, vocabulary, \n",
    "                and sentence structure. You can also use NLP tools to measure and adjust your \n",
    "                content's sentiment, emotion, and personality to match your brand voice and your \n",
    "                audience's preferences. For example, you can use a tool like Hemingway to make your \n",
    "                content more clear and concise, or use a tool like Grammarly to enhance your writing \n",
    "                skills and avoid errors.\n",
    "            '''\n",
    "print(paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tokenization**\n",
    "Convert paragraph into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "sentences = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n                NLP can also help you write better content by providing feedback, suggestions, \\n                and insights on your writing style, tone, readability, grammar, and SEO.', 'You can use NLP tools to check and improve your spelling, punctuation, vocabulary, \\n                and sentence structure.', \"You can also use NLP tools to measure and adjust your \\n                content's sentiment, emotion, and personality to match your brand voice and your \\n                audience's preferences.\", 'For example, you can use a tool like Hemingway to make your \\n                content more clear and concise, or use a tool like Grammarly to enhance your writing \\n                skills and avoid errors.']\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "histori\n",
      "goe\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "print(stemmer.stem('history'))\n",
    "print(stemmer.stem('goes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Lemmetization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmetizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history\n",
      "go\n"
     ]
    }
   ],
   "source": [
    "print(lemmetizer.lemmatize('history'))\n",
    "print(lemmetizer.lemmatize('goes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Text-preprocessing for the paragarph**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing all special charecters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                NLP can also help you write better content by providing feedback, suggestions, \n",
      "                and insights on your writing style, tone, readability, grammar, and SEO.\n",
      "You can use NLP tools to check and improve your spelling, punctuation, vocabulary, \n",
      "                and sentence structure.\n",
      "You can also use NLP tools to measure and adjust your \n",
      "                content's sentiment, emotion, and personality to match your brand voice and your \n",
      "                audience's preferences.\n",
      "For example, you can use a tool like Hemingway to make your \n",
      "                content more clear and concise, or use a tool like Grammarly to enhance your writing \n",
      "                skills and avoid errors.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "corpus = []\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    print(sentences[i])\n",
    "    review = re.sub('[^a-zA-Z]', ' ', sentences[i]).lower()\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                 nlp can also help you write better content by providing feedback  suggestions                   and insights on your writing style  tone  readability  grammar  and seo ',\n",
       " 'you can use nlp tools to check and improve your spelling  punctuation  vocabulary                   and sentence structure ',\n",
       " 'you can also use nlp tools to measure and adjust your                  content s sentiment  emotion  and personality to match your brand voice and your                  audience s preferences ',\n",
       " 'for example  you can use a tool like hemingway to make your                  content more clear and concise  or use a tool like grammarly to enhance your writing                  skills and avoid errors ']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming & Lemmatization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stem word for nlp is nlp\n",
      "lemmatizer word for nlp is nlp\n",
      "stem word for also is also\n",
      "lemmatizer word for also is also\n",
      "stem word for help is help\n",
      "lemmatizer word for help is help\n",
      "stem word for write is write\n",
      "lemmatizer word for write is write\n",
      "stem word for better is better\n",
      "lemmatizer word for better is better\n",
      "stem word for content is content\n",
      "lemmatizer word for content is content\n",
      "stem word for providing is provid\n",
      "lemmatizer word for providing is providing\n",
      "stem word for feedback is feedback\n",
      "lemmatizer word for feedback is feedback\n",
      "stem word for suggestions is suggest\n",
      "lemmatizer word for suggestions is suggestion\n",
      "stem word for insights is insight\n",
      "lemmatizer word for insights is insight\n",
      "stem word for writing is write\n",
      "lemmatizer word for writing is writing\n",
      "stem word for style is style\n",
      "lemmatizer word for style is style\n",
      "stem word for tone is tone\n",
      "lemmatizer word for tone is tone\n",
      "stem word for readability is readabl\n",
      "lemmatizer word for readability is readability\n",
      "stem word for grammar is grammar\n",
      "lemmatizer word for grammar is grammar\n",
      "stem word for seo is seo\n",
      "lemmatizer word for seo is seo\n",
      "stem word for use is use\n",
      "lemmatizer word for use is use\n",
      "stem word for nlp is nlp\n",
      "lemmatizer word for nlp is nlp\n",
      "stem word for tools is tool\n",
      "lemmatizer word for tools is tool\n",
      "stem word for check is check\n",
      "lemmatizer word for check is check\n",
      "stem word for improve is improv\n",
      "lemmatizer word for improve is improve\n",
      "stem word for spelling is spell\n",
      "lemmatizer word for spelling is spelling\n",
      "stem word for punctuation is punctuat\n",
      "lemmatizer word for punctuation is punctuation\n",
      "stem word for vocabulary is vocabulari\n",
      "lemmatizer word for vocabulary is vocabulary\n",
      "stem word for sentence is sentenc\n",
      "lemmatizer word for sentence is sentence\n",
      "stem word for structure is structur\n",
      "lemmatizer word for structure is structure\n",
      "stem word for also is also\n",
      "lemmatizer word for also is also\n",
      "stem word for use is use\n",
      "lemmatizer word for use is use\n",
      "stem word for nlp is nlp\n",
      "lemmatizer word for nlp is nlp\n",
      "stem word for tools is tool\n",
      "lemmatizer word for tools is tool\n",
      "stem word for measure is measur\n",
      "lemmatizer word for measure is measure\n",
      "stem word for adjust is adjust\n",
      "lemmatizer word for adjust is adjust\n",
      "stem word for content is content\n",
      "lemmatizer word for content is content\n",
      "stem word for sentiment is sentiment\n",
      "lemmatizer word for sentiment is sentiment\n",
      "stem word for emotion is emot\n",
      "lemmatizer word for emotion is emotion\n",
      "stem word for personality is person\n",
      "lemmatizer word for personality is personality\n",
      "stem word for match is match\n",
      "lemmatizer word for match is match\n",
      "stem word for brand is brand\n",
      "lemmatizer word for brand is brand\n",
      "stem word for voice is voic\n",
      "lemmatizer word for voice is voice\n",
      "stem word for audience is audienc\n",
      "lemmatizer word for audience is audience\n",
      "stem word for preferences is prefer\n",
      "lemmatizer word for preferences is preference\n",
      "stem word for example is exampl\n",
      "lemmatizer word for example is example\n",
      "stem word for use is use\n",
      "lemmatizer word for use is use\n",
      "stem word for tool is tool\n",
      "lemmatizer word for tool is tool\n",
      "stem word for like is like\n",
      "lemmatizer word for like is like\n",
      "stem word for hemingway is hemingway\n",
      "lemmatizer word for hemingway is hemingway\n",
      "stem word for make is make\n",
      "lemmatizer word for make is make\n",
      "stem word for content is content\n",
      "lemmatizer word for content is content\n",
      "stem word for clear is clear\n",
      "lemmatizer word for clear is clear\n",
      "stem word for concise is concis\n",
      "lemmatizer word for concise is concise\n",
      "stem word for use is use\n",
      "lemmatizer word for use is use\n",
      "stem word for tool is tool\n",
      "lemmatizer word for tool is tool\n",
      "stem word for like is like\n",
      "lemmatizer word for like is like\n",
      "stem word for grammarly is grammarli\n",
      "lemmatizer word for grammarly is grammarly\n",
      "stem word for enhance is enhanc\n",
      "lemmatizer word for enhance is enhance\n",
      "stem word for writing is write\n",
      "lemmatizer word for writing is writing\n",
      "stem word for skills is skill\n",
      "lemmatizer word for skills is skill\n",
      "stem word for avoid is avoid\n",
      "lemmatizer word for avoid is avoid\n",
      "stem word for errors is error\n",
      "lemmatizer word for errors is error\n"
     ]
    }
   ],
   "source": [
    "for sentence in corpus:  # Iterate through each sentence in corpus\n",
    "    words = nltk.word_tokenize(sentence) # Convert sentence into words using word_tokenize\n",
    "    for word in words:\n",
    "        if word not in set(stopwords.words('english')):  # If word is not present in set of english stopwrds\n",
    "            print(f\"stem word for {word} is {stemmer.stem(word)}\")\n",
    "            print(f\"lemmatizer word for {word} is {lemmetizer.lemmatize(word)}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Bag of Words (BOW)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorize = CountVectorizer(binary=True, ngram_range=(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['adjust your', 'adjust your content', 'also help', 'also help you',\n",
       "       'also use', 'also use nlp', 'and adjust', 'and adjust your',\n",
       "       'and avoid', 'and avoid errors', 'and concise', 'and concise or',\n",
       "       'and improve', 'and improve your', 'and insights',\n",
       "       'and insights on', 'and personality', 'and personality to',\n",
       "       'and sentence', 'and sentence structure', 'and seo', 'and your',\n",
       "       'and your audience', 'audience preferences', 'avoid errors',\n",
       "       'better content', 'better content by', 'brand voice',\n",
       "       'brand voice and', 'by providing', 'by providing feedback',\n",
       "       'can also', 'can also help', 'can also use', 'can use',\n",
       "       'can use nlp', 'can use tool', 'check and', 'check and improve',\n",
       "       'clear and', 'clear and concise', 'concise or', 'concise or use',\n",
       "       'content by', 'content by providing', 'content more',\n",
       "       'content more clear', 'content sentiment',\n",
       "       'content sentiment emotion', 'emotion and',\n",
       "       'emotion and personality', 'enhance your', 'enhance your writing',\n",
       "       'example you', 'example you can', 'feedback suggestions',\n",
       "       'feedback suggestions and', 'for example', 'for example you',\n",
       "       'grammar and', 'grammar and seo', 'grammarly to',\n",
       "       'grammarly to enhance', 'help you', 'help you write',\n",
       "       'hemingway to', 'hemingway to make', 'improve your',\n",
       "       'improve your spelling', 'insights on', 'insights on your',\n",
       "       'like grammarly', 'like grammarly to', 'like hemingway',\n",
       "       'like hemingway to', 'make your', 'make your content',\n",
       "       'match your', 'match your brand', 'measure and',\n",
       "       'measure and adjust', 'more clear', 'more clear and', 'nlp can',\n",
       "       'nlp can also', 'nlp tools', 'nlp tools to', 'on your',\n",
       "       'on your writing', 'or use', 'or use tool', 'personality to',\n",
       "       'personality to match', 'providing feedback',\n",
       "       'providing feedback suggestions', 'punctuation vocabulary',\n",
       "       'punctuation vocabulary and', 'readability grammar',\n",
       "       'readability grammar and', 'sentence structure',\n",
       "       'sentiment emotion', 'sentiment emotion and', 'skills and',\n",
       "       'skills and avoid', 'spelling punctuation',\n",
       "       'spelling punctuation vocabulary', 'style tone',\n",
       "       'style tone readability', 'suggestions and',\n",
       "       'suggestions and insights', 'to check', 'to check and',\n",
       "       'to enhance', 'to enhance your', 'to make', 'to make your',\n",
       "       'to match', 'to match your', 'to measure', 'to measure and',\n",
       "       'tone readability', 'tone readability grammar', 'tool like',\n",
       "       'tool like grammarly', 'tool like hemingway', 'tools to',\n",
       "       'tools to check', 'tools to measure', 'use nlp', 'use nlp tools',\n",
       "       'use tool', 'use tool like', 'vocabulary and',\n",
       "       'vocabulary and sentence', 'voice and', 'voice and your',\n",
       "       'write better', 'write better content', 'writing skills',\n",
       "       'writing skills and', 'writing style', 'writing style tone',\n",
       "       'you can', 'you can also', 'you can use', 'you write',\n",
       "       'you write better', 'your audience', 'your audience preferences',\n",
       "       'your brand', 'your brand voice', 'your content',\n",
       "       'your content more', 'your content sentiment', 'your spelling',\n",
       "       'your spelling punctuation', 'your writing', 'your writing skills',\n",
       "       'your writing style'], dtype=object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = count_vectorize.fit_transform(corpus)\n",
    "count_vectorize.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nlp can': 83,\n",
       " 'can also': 31,\n",
       " 'also help': 2,\n",
       " 'help you': 63,\n",
       " 'you write': 145,\n",
       " 'write better': 136,\n",
       " 'better content': 25,\n",
       " 'content by': 43,\n",
       " 'by providing': 29,\n",
       " 'providing feedback': 93,\n",
       " 'feedback suggestions': 55,\n",
       " 'suggestions and': 108,\n",
       " 'and insights': 14,\n",
       " 'insights on': 69,\n",
       " 'on your': 87,\n",
       " 'your writing': 156,\n",
       " 'writing style': 140,\n",
       " 'style tone': 106,\n",
       " 'tone readability': 120,\n",
       " 'readability grammar': 97,\n",
       " 'grammar and': 59,\n",
       " 'and seo': 20,\n",
       " 'nlp can also': 84,\n",
       " 'can also help': 32,\n",
       " 'also help you': 3,\n",
       " 'help you write': 64,\n",
       " 'you write better': 146,\n",
       " 'write better content': 137,\n",
       " 'better content by': 26,\n",
       " 'content by providing': 44,\n",
       " 'by providing feedback': 30,\n",
       " 'providing feedback suggestions': 94,\n",
       " 'feedback suggestions and': 56,\n",
       " 'suggestions and insights': 109,\n",
       " 'and insights on': 15,\n",
       " 'insights on your': 70,\n",
       " 'on your writing': 88,\n",
       " 'your writing style': 158,\n",
       " 'writing style tone': 141,\n",
       " 'style tone readability': 107,\n",
       " 'tone readability grammar': 121,\n",
       " 'readability grammar and': 98,\n",
       " 'grammar and seo': 60,\n",
       " 'you can': 142,\n",
       " 'can use': 34,\n",
       " 'use nlp': 128,\n",
       " 'nlp tools': 85,\n",
       " 'tools to': 125,\n",
       " 'to check': 110,\n",
       " 'check and': 37,\n",
       " 'and improve': 12,\n",
       " 'improve your': 67,\n",
       " 'your spelling': 154,\n",
       " 'spelling punctuation': 104,\n",
       " 'punctuation vocabulary': 95,\n",
       " 'vocabulary and': 132,\n",
       " 'and sentence': 18,\n",
       " 'sentence structure': 99,\n",
       " 'you can use': 144,\n",
       " 'can use nlp': 35,\n",
       " 'use nlp tools': 129,\n",
       " 'nlp tools to': 86,\n",
       " 'tools to check': 126,\n",
       " 'to check and': 111,\n",
       " 'check and improve': 38,\n",
       " 'and improve your': 13,\n",
       " 'improve your spelling': 68,\n",
       " 'your spelling punctuation': 155,\n",
       " 'spelling punctuation vocabulary': 105,\n",
       " 'punctuation vocabulary and': 96,\n",
       " 'vocabulary and sentence': 133,\n",
       " 'and sentence structure': 19,\n",
       " 'also use': 4,\n",
       " 'to measure': 118,\n",
       " 'measure and': 79,\n",
       " 'and adjust': 6,\n",
       " 'adjust your': 0,\n",
       " 'your content': 151,\n",
       " 'content sentiment': 47,\n",
       " 'sentiment emotion': 100,\n",
       " 'emotion and': 49,\n",
       " 'and personality': 16,\n",
       " 'personality to': 91,\n",
       " 'to match': 116,\n",
       " 'match your': 77,\n",
       " 'your brand': 149,\n",
       " 'brand voice': 27,\n",
       " 'voice and': 134,\n",
       " 'and your': 21,\n",
       " 'your audience': 147,\n",
       " 'audience preferences': 23,\n",
       " 'you can also': 143,\n",
       " 'can also use': 33,\n",
       " 'also use nlp': 5,\n",
       " 'tools to measure': 127,\n",
       " 'to measure and': 119,\n",
       " 'measure and adjust': 80,\n",
       " 'and adjust your': 7,\n",
       " 'adjust your content': 1,\n",
       " 'your content sentiment': 153,\n",
       " 'content sentiment emotion': 48,\n",
       " 'sentiment emotion and': 101,\n",
       " 'emotion and personality': 50,\n",
       " 'and personality to': 17,\n",
       " 'personality to match': 92,\n",
       " 'to match your': 117,\n",
       " 'match your brand': 78,\n",
       " 'your brand voice': 150,\n",
       " 'brand voice and': 28,\n",
       " 'voice and your': 135,\n",
       " 'and your audience': 22,\n",
       " 'your audience preferences': 148,\n",
       " 'for example': 57,\n",
       " 'example you': 53,\n",
       " 'use tool': 130,\n",
       " 'tool like': 122,\n",
       " 'like hemingway': 73,\n",
       " 'hemingway to': 65,\n",
       " 'to make': 114,\n",
       " 'make your': 75,\n",
       " 'content more': 45,\n",
       " 'more clear': 81,\n",
       " 'clear and': 39,\n",
       " 'and concise': 10,\n",
       " 'concise or': 41,\n",
       " 'or use': 89,\n",
       " 'like grammarly': 71,\n",
       " 'grammarly to': 61,\n",
       " 'to enhance': 112,\n",
       " 'enhance your': 51,\n",
       " 'writing skills': 138,\n",
       " 'skills and': 102,\n",
       " 'and avoid': 8,\n",
       " 'avoid errors': 24,\n",
       " 'for example you': 58,\n",
       " 'example you can': 54,\n",
       " 'can use tool': 36,\n",
       " 'use tool like': 131,\n",
       " 'tool like hemingway': 124,\n",
       " 'like hemingway to': 74,\n",
       " 'hemingway to make': 66,\n",
       " 'to make your': 115,\n",
       " 'make your content': 76,\n",
       " 'your content more': 152,\n",
       " 'content more clear': 46,\n",
       " 'more clear and': 82,\n",
       " 'clear and concise': 40,\n",
       " 'and concise or': 11,\n",
       " 'concise or use': 42,\n",
       " 'or use tool': 90,\n",
       " 'tool like grammarly': 123,\n",
       " 'like grammarly to': 72,\n",
       " 'grammarly to enhance': 62,\n",
       " 'to enhance your': 113,\n",
       " 'enhance your writing': 52,\n",
       " 'your writing skills': 157,\n",
       " 'writing skills and': 139,\n",
       " 'skills and avoid': 103,\n",
       " 'and avoid errors': 9}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorize.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **What does the CountVectorizer does?**\n",
    "\n",
    "- So CountVectorizer will create a sparse matrix of vocabulary from the corpus\n",
    "- get_feature_names_out() this method gives us the list of words in vocabulary.\n",
    "- vocabulary_ gives us the word index in vocabulary\n",
    "- If we want binary BOW then we can set binary to True\n",
    "- Also we can use ngrams to create a pair of words if we use (3,3) then it will create trigrams.\n",
    "- If we use (2, 3) then it will first create bigrams and after that it will create trigrams as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                 nlp can also help you write better content by providing feedback  suggestions                   and insights on your writing style  tone  readability  grammar  and seo '"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "        0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "        1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This will give us a clear idea that Bag Of Words for 1st sentence has second element from vocabulary which is also. so here we are given 1.\n",
    "- and is present 2 times hence we have given 2.\n",
    "- If we use Binary = True then we will get only 0 & 1 even if the word is present more than once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X = tfidf.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                 nlp can also help you write better content by providing feedback  suggestions                   and insights on your writing style  tone  readability  grammar  and seo '"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.18601526, 0.24624319, 0.        , 0.        ,\n",
       "        0.23593677, 0.        , 0.23593677, 0.12312159, 0.        ,\n",
       "        0.        , 0.        , 0.15059538, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.23593677, 0.        , 0.23593677,\n",
       "        0.        , 0.23593677, 0.        , 0.        , 0.23593677,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.15059538, 0.23593677, 0.        , 0.        , 0.        ,\n",
       "        0.23593677, 0.        , 0.23593677, 0.        , 0.        ,\n",
       "        0.23593677, 0.        , 0.        , 0.        , 0.23593677,\n",
       "        0.23593677, 0.        , 0.23593677, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.23593677, 0.18601526,\n",
       "        0.12312159, 0.12312159]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So here we are getting different values to different words instead of just 1 & 0.\n",
    "- So in this way we are capturing the important words from the sentences.\n",
    "- Here also we can use ngrams, to pair up the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
