{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                NLP can also help you write better content by providing feedback, suggestions, \n",
      "                and insights on your writing style, tone, readability, grammar, and SEO. \n",
      "                You can use NLP tools to check and improve your spelling, punctuation, vocabulary, \n",
      "                and sentence structure. You can also use NLP tools to measure and adjust your \n",
      "                content's sentiment, emotion, and personality to match your brand voice and your \n",
      "                audience's preferences. For example, you can use a tool like Hemingway to make your \n",
      "                content more clear and concise, or use a tool like Grammarly to enhance your writing \n",
      "                skills and avoid errors.\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "paragraph = '''\n",
    "                NLP can also help you write better content by providing feedback, suggestions, \n",
    "                and insights on your writing style, tone, readability, grammar, and SEO. \n",
    "                You can use NLP tools to check and improve your spelling, punctuation, vocabulary, \n",
    "                and sentence structure. You can also use NLP tools to measure and adjust your \n",
    "                content's sentiment, emotion, and personality to match your brand voice and your \n",
    "                audience's preferences. For example, you can use a tool like Hemingway to make your \n",
    "                content more clear and concise, or use a tool like Grammarly to enhance your writing \n",
    "                skills and avoid errors.\n",
    "            '''\n",
    "print(paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tokenization**\n",
    "Convert paragraph into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "sentences = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n                NLP can also help you write better content by providing feedback, suggestions, \\n                and insights on your writing style, tone, readability, grammar, and SEO.', 'You can use NLP tools to check and improve your spelling, punctuation, vocabulary, \\n                and sentence structure.', \"You can also use NLP tools to measure and adjust your \\n                content's sentiment, emotion, and personality to match your brand voice and your \\n                audience's preferences.\", 'For example, you can use a tool like Hemingway to make your \\n                content more clear and concise, or use a tool like Grammarly to enhance your writing \\n                skills and avoid errors.']\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "histori\n",
      "goe\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "print(stemmer.stem('history'))\n",
    "print(stemmer.stem('goes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Lemmetization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmetizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history\n",
      "go\n"
     ]
    }
   ],
   "source": [
    "print(lemmetizer.lemmatize('history'))\n",
    "print(lemmetizer.lemmatize('goes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Text-preprocessing for the paragarph**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing all special charecters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                NLP can also help you write better content by providing feedback, suggestions, \n",
      "                and insights on your writing style, tone, readability, grammar, and SEO.\n",
      "You can use NLP tools to check and improve your spelling, punctuation, vocabulary, \n",
      "                and sentence structure.\n",
      "You can also use NLP tools to measure and adjust your \n",
      "                content's sentiment, emotion, and personality to match your brand voice and your \n",
      "                audience's preferences.\n",
      "For example, you can use a tool like Hemingway to make your \n",
      "                content more clear and concise, or use a tool like Grammarly to enhance your writing \n",
      "                skills and avoid errors.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "corpus = []\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    print(sentences[i])\n",
    "    review = re.sub('[^a-zA-Z]', ' ', sentences[i]).lower()\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                 nlp can also help you write better content by providing feedback  suggestions                   and insights on your writing style  tone  readability  grammar  and seo ',\n",
       " 'you can use nlp tools to check and improve your spelling  punctuation  vocabulary                   and sentence structure ',\n",
       " 'you can also use nlp tools to measure and adjust your                  content s sentiment  emotion  and personality to match your brand voice and your                  audience s preferences ',\n",
       " 'for example  you can use a tool like hemingway to make your                  content more clear and concise  or use a tool like grammarly to enhance your writing                  skills and avoid errors ']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming & Lemmatization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stem word for nlp is nlp\n",
      "lemmatizer word for nlp is nlp\n",
      "stem word for also is also\n",
      "lemmatizer word for also is also\n",
      "stem word for help is help\n",
      "lemmatizer word for help is help\n",
      "stem word for write is write\n",
      "lemmatizer word for write is write\n",
      "stem word for better is better\n",
      "lemmatizer word for better is better\n",
      "stem word for content is content\n",
      "lemmatizer word for content is content\n",
      "stem word for providing is provid\n",
      "lemmatizer word for providing is providing\n",
      "stem word for feedback is feedback\n",
      "lemmatizer word for feedback is feedback\n",
      "stem word for suggestions is suggest\n",
      "lemmatizer word for suggestions is suggestion\n",
      "stem word for insights is insight\n",
      "lemmatizer word for insights is insight\n",
      "stem word for writing is write\n",
      "lemmatizer word for writing is writing\n",
      "stem word for style is style\n",
      "lemmatizer word for style is style\n",
      "stem word for tone is tone\n",
      "lemmatizer word for tone is tone\n",
      "stem word for readability is readabl\n",
      "lemmatizer word for readability is readability\n",
      "stem word for grammar is grammar\n",
      "lemmatizer word for grammar is grammar\n",
      "stem word for seo is seo\n",
      "lemmatizer word for seo is seo\n",
      "stem word for use is use\n",
      "lemmatizer word for use is use\n",
      "stem word for nlp is nlp\n",
      "lemmatizer word for nlp is nlp\n",
      "stem word for tools is tool\n",
      "lemmatizer word for tools is tool\n",
      "stem word for check is check\n",
      "lemmatizer word for check is check\n",
      "stem word for improve is improv\n",
      "lemmatizer word for improve is improve\n",
      "stem word for spelling is spell\n",
      "lemmatizer word for spelling is spelling\n",
      "stem word for punctuation is punctuat\n",
      "lemmatizer word for punctuation is punctuation\n",
      "stem word for vocabulary is vocabulari\n",
      "lemmatizer word for vocabulary is vocabulary\n",
      "stem word for sentence is sentenc\n",
      "lemmatizer word for sentence is sentence\n",
      "stem word for structure is structur\n",
      "lemmatizer word for structure is structure\n",
      "stem word for also is also\n",
      "lemmatizer word for also is also\n",
      "stem word for use is use\n",
      "lemmatizer word for use is use\n",
      "stem word for nlp is nlp\n",
      "lemmatizer word for nlp is nlp\n",
      "stem word for tools is tool\n",
      "lemmatizer word for tools is tool\n",
      "stem word for measure is measur\n",
      "lemmatizer word for measure is measure\n",
      "stem word for adjust is adjust\n",
      "lemmatizer word for adjust is adjust\n",
      "stem word for content is content\n",
      "lemmatizer word for content is content\n",
      "stem word for sentiment is sentiment\n",
      "lemmatizer word for sentiment is sentiment\n",
      "stem word for emotion is emot\n",
      "lemmatizer word for emotion is emotion\n",
      "stem word for personality is person\n",
      "lemmatizer word for personality is personality\n",
      "stem word for match is match\n",
      "lemmatizer word for match is match\n",
      "stem word for brand is brand\n",
      "lemmatizer word for brand is brand\n",
      "stem word for voice is voic\n",
      "lemmatizer word for voice is voice\n",
      "stem word for audience is audienc\n",
      "lemmatizer word for audience is audience\n",
      "stem word for preferences is prefer\n",
      "lemmatizer word for preferences is preference\n",
      "stem word for example is exampl\n",
      "lemmatizer word for example is example\n",
      "stem word for use is use\n",
      "lemmatizer word for use is use\n",
      "stem word for tool is tool\n",
      "lemmatizer word for tool is tool\n",
      "stem word for like is like\n",
      "lemmatizer word for like is like\n",
      "stem word for hemingway is hemingway\n",
      "lemmatizer word for hemingway is hemingway\n",
      "stem word for make is make\n",
      "lemmatizer word for make is make\n",
      "stem word for content is content\n",
      "lemmatizer word for content is content\n",
      "stem word for clear is clear\n",
      "lemmatizer word for clear is clear\n",
      "stem word for concise is concis\n",
      "lemmatizer word for concise is concise\n",
      "stem word for use is use\n",
      "lemmatizer word for use is use\n",
      "stem word for tool is tool\n",
      "lemmatizer word for tool is tool\n",
      "stem word for like is like\n",
      "lemmatizer word for like is like\n",
      "stem word for grammarly is grammarli\n",
      "lemmatizer word for grammarly is grammarly\n",
      "stem word for enhance is enhanc\n",
      "lemmatizer word for enhance is enhance\n",
      "stem word for writing is write\n",
      "lemmatizer word for writing is writing\n",
      "stem word for skills is skill\n",
      "lemmatizer word for skills is skill\n",
      "stem word for avoid is avoid\n",
      "lemmatizer word for avoid is avoid\n",
      "stem word for errors is error\n",
      "lemmatizer word for errors is error\n"
     ]
    }
   ],
   "source": [
    "for sentence in corpus:  # Iterate through each sentence in corpus\n",
    "    words = nltk.word_tokenize(sentence) # Convert sentence into words using word_tokenize\n",
    "    for word in words:\n",
    "        if word not in set(stopwords.words('english')):  # If word is not present in set of english stopwrds\n",
    "            print(f\"stem word for {word} is {stemmer.stem(word)}\")\n",
    "            print(f\"lemmatizer word for {word} is {lemmetizer.lemmatize(word)}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Bag of Words (BOW)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorize = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['adjust', 'also', 'and', 'audience', 'avoid', 'better', 'brand',\n",
       "       'by', 'can', 'check', 'clear', 'concise', 'content', 'emotion',\n",
       "       'enhance', 'errors', 'example', 'feedback', 'for', 'grammar',\n",
       "       'grammarly', 'help', 'hemingway', 'improve', 'insights', 'like',\n",
       "       'make', 'match', 'measure', 'more', 'nlp', 'on', 'or',\n",
       "       'personality', 'preferences', 'providing', 'punctuation',\n",
       "       'readability', 'sentence', 'sentiment', 'seo', 'skills',\n",
       "       'spelling', 'structure', 'style', 'suggestions', 'to', 'tone',\n",
       "       'tool', 'tools', 'use', 'vocabulary', 'voice', 'write', 'writing',\n",
       "       'you', 'your'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = count_vectorize.fit_transform(corpus)\n",
    "count_vectorize.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nlp': 30,\n",
       " 'can': 8,\n",
       " 'also': 1,\n",
       " 'help': 21,\n",
       " 'you': 55,\n",
       " 'write': 53,\n",
       " 'better': 5,\n",
       " 'content': 12,\n",
       " 'by': 7,\n",
       " 'providing': 35,\n",
       " 'feedback': 17,\n",
       " 'suggestions': 45,\n",
       " 'and': 2,\n",
       " 'insights': 24,\n",
       " 'on': 31,\n",
       " 'your': 56,\n",
       " 'writing': 54,\n",
       " 'style': 44,\n",
       " 'tone': 47,\n",
       " 'readability': 37,\n",
       " 'grammar': 19,\n",
       " 'seo': 40,\n",
       " 'use': 50,\n",
       " 'tools': 49,\n",
       " 'to': 46,\n",
       " 'check': 9,\n",
       " 'improve': 23,\n",
       " 'spelling': 42,\n",
       " 'punctuation': 36,\n",
       " 'vocabulary': 51,\n",
       " 'sentence': 38,\n",
       " 'structure': 43,\n",
       " 'measure': 28,\n",
       " 'adjust': 0,\n",
       " 'sentiment': 39,\n",
       " 'emotion': 13,\n",
       " 'personality': 33,\n",
       " 'match': 27,\n",
       " 'brand': 6,\n",
       " 'voice': 52,\n",
       " 'audience': 3,\n",
       " 'preferences': 34,\n",
       " 'for': 18,\n",
       " 'example': 16,\n",
       " 'tool': 48,\n",
       " 'like': 25,\n",
       " 'hemingway': 22,\n",
       " 'make': 26,\n",
       " 'more': 29,\n",
       " 'clear': 10,\n",
       " 'concise': 11,\n",
       " 'or': 32,\n",
       " 'grammarly': 20,\n",
       " 'enhance': 14,\n",
       " 'skills': 41,\n",
       " 'avoid': 4,\n",
       " 'errors': 15}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorize.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **What does the CountVectorizer does?**\n",
    "\n",
    "- So CountVectorizer will create a sparse matrix of vocabulary from the corpus\n",
    "- get_feature_names_out() this method gives us the list of words in vocabulary.\n",
    "- vocabulary_ gives us the word index in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                 nlp can also help you write better content by providing feedback  suggestions                   and insights on your writing style  tone  readability  grammar  and seo '"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This will give us a clear idea that Bag Of Words for 1st sentence has second element from vocabulary which is also. so here we are given 1.\n",
    "- and is present 2 times hence we have given 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
